{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d64e757",
   "metadata": {},
   "source": [
    "# Example model and use of the MOD PTB Microbiome challenge data\n",
    "\n",
    "*Microbiome data* has a few quirks for machine learning applications. Here I will go through an example using what I feel is the best feature type to use for ML-microbiome studies. \n",
    "\n",
    "**TL/DR: Use the phylotype tables and/or alpha-diversity and/or pairwise distance and/or CST** instead of taxonomy or raw sequence-variant counts, as the former are the best harmonized across datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8af5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import plot_roc_curve, roc_curve, roc_auc_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065e789",
   "metadata": {},
   "source": [
    "I do my ML in python. The raw data are almost all in `csv` format, which should import into a variety of engines without fuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b71aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR = '../../training_data/training_data_2022-05-27/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378fed78",
   "metadata": {},
   "source": [
    "This is the path to the training data, in turn with the following subdirectories and files:\n",
    "\n",
    "```\n",
    "├── alpha_diversity\n",
    "│  └── alpha_diversity.csv\n",
    "├── community_state_types\n",
    "│  ├── cst_valencia.csv\n",
    "│  └── cst_valencia_w_taxons.csv\n",
    "├── metadata\n",
    "│  └── metadata.csv\n",
    "├── pairwise_distance\n",
    "│  ├── krd_distance_long.csv\n",
    "│  └── krd_distance_wide.csv\n",
    "├── phylotypes\n",
    "│  ├── phylotype_nreads.1e0.csv\n",
    "│  ├── phylotype_nreads.1e_1.csv\n",
    "│  ├── phylotype_nreads.5e_1.csv\n",
    "│  ├── phylotype_relabd.1e0.csv\n",
    "│  ├── phylotype_relabd.1e_1.csv\n",
    "│  ├── phylotype_relabd.5e_1.csv\n",
    "│  ├── pt.1e-1.csv\n",
    "│  ├── pt.1e0.csv\n",
    "│  └── pt.5e-1.csv\n",
    "├── sv_counts\n",
    "│  └── sp_sv_long.csv\n",
    "└── taxonomy\n",
    "   ├── sv_taxonomy.csv\n",
    "   ├── taxonomy_nreads.family.csv\n",
    "   ├── taxonomy_nreads.genus.csv\n",
    "   ├── taxonomy_nreads.species.csv\n",
    "   ├── taxonomy_relabd.family.csv\n",
    "   ├── taxonomy_relabd.genus.csv\n",
    "   └── taxonomy_relabd.species.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abeed997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project</th>\n",
       "      <th>specimen</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>was_term</th>\n",
       "      <th>delivery_wk</th>\n",
       "      <th>collect_wk</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>NIH Racial Category</th>\n",
       "      <th>NIH Ethnicity Category</th>\n",
       "      <th>was_preterm</th>\n",
       "      <th>was_early_preterm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A00001-05</td>\n",
       "      <td>A00001</td>\n",
       "      <td>True</td>\n",
       "      <td>38.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>American Indian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>A00002-01</td>\n",
       "      <td>A00002</td>\n",
       "      <td>True</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>A00003-02</td>\n",
       "      <td>A00003</td>\n",
       "      <td>True</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Asian-Japanese</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  project   specimen participant_id  was_term  delivery_wk  collect_wk  \\\n",
       "0       A  A00001-05         A00001      True         38.0        33.0   \n",
       "1       A  A00002-01         A00002      True         40.0        38.0   \n",
       "2       A  A00003-02         A00003      True         40.0        30.0   \n",
       "\n",
       "              race      age               NIH Racial Category  \\\n",
       "0  American Indian  Unknown  American Indian or Alaska Native   \n",
       "1            White  Unknown                             White   \n",
       "2   Asian-Japanese  Unknown                             Asian   \n",
       "\n",
       "  NIH Ethnicity Category  was_preterm  was_early_preterm  \n",
       "0                Unknown        False              False  \n",
       "1                Unknown        False              False  \n",
       "2                Unknown        False              False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\n",
    "    os.path.join(BASEDIR, 'metadata', 'metadata.csv')\n",
    ")\n",
    "metadata.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f3aeb7",
   "metadata": {},
   "source": [
    "**metadata** is provided for both the training and validation data sets. In our simple model today, we will not correct for things like age, gestational week of collection of the specimen, race, ethnicity, etc.\n",
    "\n",
    "The validation data will lack the outcome data (e.g. `was_preterm`, `was_early_preterm`, `was_term` and `delivery_wk` columns).\n",
    "\n",
    "For convenience, I convert the metadata into associative dictionaries to be able to quickly look up crucial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d669acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some per-participant values\n",
    "\n",
    "specimen_participant = {\n",
    "    sp: p\n",
    "    for (sp, p) in zip(\n",
    "        metadata.specimen,\n",
    "        metadata.participant_id\n",
    "    )\n",
    "}\n",
    "len(specimen_participant)\n",
    "\n",
    "participant_preterm = {\n",
    "    p: pt\n",
    "    for (p, pt)\n",
    "    in zip(\n",
    "        metadata.participant_id,\n",
    "        metadata.was_preterm\n",
    "    )\n",
    "}\n",
    "participant_earlypreterm = {\n",
    "    p: pt\n",
    "    for (p, pt)\n",
    "    in zip(\n",
    "        metadata.participant_id,\n",
    "        metadata.was_early_preterm\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d472921",
   "metadata": {},
   "source": [
    "Validation data will be limited to through 32 weeks for the preterm challenge and through 28 weeks for the early-preterm challenge. Let's do the same to the training data to be sure we are not relying upon later-in-pregnancy specimens we will not have access to in the validation set....\n",
    "\n",
    "We will then further split the training data into a train-test set at 70-30 to be able to check on our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74de195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849 365 2240 949\n",
      "809 348 1999 869\n"
     ]
    }
   ],
   "source": [
    "    # Make a split 70-30 *by participant* (to ensure no leak from a person's specimens between test/train)\n",
    "    all_participants = sorted(metadata[metadata.collect_wk <= 32].participant_id.unique())\n",
    "    early_participants = sorted(metadata[metadata.collect_wk <= 28].participant_id.unique())\n",
    "\n",
    "    random.seed(12345)\n",
    "    train_participants = random.sample(all_participants, int(0.7*len(all_participants)))\n",
    "    test_participants = [p for p in all_participants if p not in train_participants]\n",
    "    train_specimens = list(metadata[\n",
    "        metadata.participant_id.apply(lambda p: p in train_participants) &\n",
    "        (metadata.collect_wk <= 32)\n",
    "    ].specimen)\n",
    "    test_specimens = list(metadata[\n",
    "        metadata.participant_id.apply(lambda p: p in test_participants) &\n",
    "        (metadata.collect_wk <= 32)\n",
    "    ].specimen)\n",
    "\n",
    "    print(\n",
    "        len(train_participants),\n",
    "        len(test_participants),\n",
    "        len(train_specimens),\n",
    "        len(test_specimens)\n",
    "    )\n",
    "    #--- Now early PTB\n",
    "    train_participants_early = random.sample(early_participants, int(0.7*len(early_participants)))\n",
    "    test_participants_early = [p for p in early_participants if p not in train_participants_early]\n",
    "    train_specimens_early = list(metadata[\n",
    "        metadata.participant_id.apply(lambda p: p in train_participants_early) &\n",
    "        (metadata.collect_wk <= 28)\n",
    "    ].specimen)\n",
    "    test_specimens_early = list(metadata[\n",
    "        metadata.participant_id.apply(lambda p: p in test_participants_early) &\n",
    "        (metadata.collect_wk <= 28)\n",
    "    ].specimen)\n",
    "\n",
    "    print(\n",
    "        len(train_participants_early),\n",
    "        len(test_participants_early),\n",
    "        len(train_specimens_early),\n",
    "        len(test_specimens_early)\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9430174",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Make an outcome lookup dict for preterm / not-preterm\n",
    "\n",
    "    preterm_tf = {\n",
    "        sp: bool(t)\n",
    "        for (sp, t) in\n",
    "        zip(\n",
    "            metadata[metadata.participant_id.apply(lambda p: p in all_participants)].specimen,\n",
    "            metadata[metadata.participant_id.apply(lambda p: p in all_participants)].was_preterm\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Make our test-train splits on the outcome data\n",
    "\n",
    "    preterm_tf_train = [\n",
    "        preterm_tf.get(p)\n",
    "        for p in \n",
    "        train_specimens\n",
    "    ]\n",
    "    preterm_tf_test = [\n",
    "        preterm_tf.get(p)\n",
    "        for p in \n",
    "        test_specimens\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Make an outcome lookup dict for early_preterm / not-early_preterm\n",
    "\n",
    "    early_preterm_tf = {\n",
    "        sp: bool(t)\n",
    "        for (sp, t) in\n",
    "        zip(\n",
    "            metadata[metadata.participant_id.apply(lambda p: p in early_participants)].specimen,\n",
    "            metadata[metadata.participant_id.apply(lambda p: p in early_participants)].was_early_preterm\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Make our test-train splits on the outcome data\n",
    "\n",
    "    early_preterm_tf_train = [\n",
    "        early_preterm_tf.get(p)\n",
    "        for p in \n",
    "        train_specimens_early\n",
    "    ]\n",
    "    early_preterm_tf_test = [\n",
    "        early_preterm_tf.get(p)\n",
    "        for p in \n",
    "        test_specimens_early\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bfd7c",
   "metadata": {},
   "source": [
    "## For this model, we will ONLY use the phylotype-relative abundance data.\n",
    "\n",
    "Phylotypes are a cross-study feature, representing either a microbe, or very closely related (in evolutionary time) set of microbes. \n",
    "\n",
    "Phylotypes are groups of 16S rRNA sequence variants that have been clustered together based on the phylogenetic distance between these sequence variants after placement onto a tree of full-length 16S rRNA alleles. These were generated using the [MaLiAmPi pipeline](https://github.com/jgolob/maliampi).\n",
    "\n",
    "If you are not sure which feature to use, I suggest *trying your modeling first with phylotypes as the feature*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de230f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Load in the phylotype data\n",
    "    pt_ra_1e_1 = pd.read_csv(\n",
    "        os.path.join(BASEDIR, 'phylotypes', 'phylotype_relabd.1e_1.csv'),\n",
    "        index_col=0\n",
    "    )\n",
    "    pt_ra_5e_1 = pd.read_csv(\n",
    "        os.path.join(BASEDIR, 'phylotypes', 'phylotype_relabd.5e_1.csv'),\n",
    "        index_col=0\n",
    "    )\n",
    "    pt_ra_1e0 = pd.read_csv(\n",
    "        os.path.join(BASEDIR, 'phylotypes', 'phylotype_relabd.1e0.csv'),\n",
    "        index_col=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1d6c6",
   "metadata": {},
   "source": [
    "These phylotype feature tables are very akin to OTU tables used in other forms of microbiome analysis or a FPKM table from a transcriptioanl data set. Each specimen is a row. Each feature gets a column. The values are the relative transcripts that belong to that feature for that specimen...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c42661",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ra_5e_1.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34526a97",
   "metadata": {},
   "source": [
    "Sum up by row and the total is always 1.0, as these are normalized relative abundance. The `nreads` versions of these same tables have the raw read counts per specimen, suitable for things like beta-binomial modeling, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e897ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_ra_5e_1.T.sum().iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc8732",
   "metadata": {},
   "source": [
    "You can see there are *three* tables loaded, one clustering at a different phylogenetic distance. This way, we can see the effect of this hyperparameter: the phylogenetic distance used to cluster together sequence variants.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f19399",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Test / train split the phylotype data at three different phylogenetic distances for clustering:\n",
    "    # 1 (1e0)\n",
    "    # 0.5 (5e-1)\n",
    "    # 0.1 (1e-1)\n",
    "    # The lower distances keep more information about strain differences, \n",
    "    # but make integration of different studies more challenging\n",
    "    pt_ra_1e_1_train = pt_ra_1e_1.loc[train_specimens]\n",
    "    pt_ra_1e_1_test = pt_ra_1e_1.loc[test_specimens]\n",
    "\n",
    "    pt_ra_5e_1_train = pt_ra_5e_1.loc[train_specimens]\n",
    "    pt_ra_5e_1_test = pt_ra_5e_1.loc[test_specimens]\n",
    "\n",
    "    pt_ra_1e0_train = pt_ra_1e0.loc[train_specimens]\n",
    "    pt_ra_1e0_test = pt_ra_1e0.loc[test_specimens]\n",
    "    \n",
    "    # -- Early\n",
    "    pt_ra_1e_1_train_early = pt_ra_1e_1.loc[train_specimens_early]\n",
    "    pt_ra_1e_1_test_early = pt_ra_1e_1.loc[test_specimens_early]\n",
    "\n",
    "    pt_ra_5e_1_train_early = pt_ra_5e_1.loc[train_specimens_early]\n",
    "    pt_ra_5e_1_test_early = pt_ra_5e_1.loc[test_specimens_early]\n",
    "\n",
    "    pt_ra_1e0_train_early = pt_ra_1e0.loc[train_specimens_early]\n",
    "    pt_ra_1e0_test_early = pt_ra_1e0.loc[test_specimens_early]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79630f4",
   "metadata": {},
   "source": [
    "This is the actual modeling, with a random forest classifer. This is a very basic model with no optimization of hyperparameters. The intent was just to make a model suitable for developing the validation pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_rf_model_1e0_preterm = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    random_state=12345\n",
    ").fit(\n",
    "    X=pt_ra_1e0_train,\n",
    "    y=preterm_tf_train\n",
    ")\n",
    "\n",
    "# And now score the model on the training and test specimens....\n",
    "print(\n",
    "    pt_rf_model_1e0_preterm.score(\n",
    "        X=pt_ra_1e0_train,\n",
    "        y=preterm_tf_train\n",
    "    ),\n",
    "    pt_rf_model_1e0_preterm.score(\n",
    "        X=pt_ra_1e0_test,\n",
    "        y=preterm_tf_test\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "pt_rf_model_1e0_early_preterm = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    random_state=12345\n",
    ").fit(\n",
    "    X=pt_ra_1e0_train_early,\n",
    "    y=early_preterm_tf_train\n",
    ")\n",
    "\n",
    "# And now score the model on the training and test specimens....\n",
    "print(\n",
    "    pt_rf_model_1e0_early_preterm.score(\n",
    "        X=pt_ra_1e0_train_early,\n",
    "        y=early_preterm_tf_train\n",
    "    ),\n",
    "    pt_rf_model_1e0_early_preterm.score(\n",
    "        X=pt_ra_1e0_test_early,\n",
    "        y=early_preterm_tf_test\n",
    "    ),\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_rf_model_5e_1_preterm = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    random_state=12345\n",
    ").fit(\n",
    "    X=pt_ra_5e_1_train,\n",
    "    y=preterm_tf_train\n",
    ")\n",
    "\n",
    "# And now score the model on the training and test specimens....\n",
    "print(\n",
    "    pt_rf_model_5e_1_preterm.score(\n",
    "        X=pt_ra_5e_1_train,\n",
    "        y=preterm_tf_train\n",
    "    ),\n",
    "    pt_rf_model_5e_1_preterm.score(\n",
    "        X=pt_ra_5e_1_test,\n",
    "        y=preterm_tf_test\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "pt_rf_model_5e_1_early_preterm = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    random_state=12345\n",
    ").fit(\n",
    "    X=pt_ra_5e_1_train_early,\n",
    "    y=early_preterm_tf_train\n",
    ")\n",
    "\n",
    "# And now score the model on the training and test specimens....\n",
    "print(\n",
    "    pt_rf_model_5e_1_early_preterm.score(\n",
    "        X=pt_ra_5e_1_train_early,\n",
    "        y=early_preterm_tf_train\n",
    "    ),\n",
    "    pt_rf_model_5e_1_early_preterm.score(\n",
    "        X=pt_ra_5e_1_test_early,\n",
    "        y=early_preterm_tf_test\n",
    "    ),\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd654257",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_rf_model_1e_1_preterm = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    random_state=12345\n",
    ").fit(\n",
    "    X=pt_ra_1e_1_train,\n",
    "    y=preterm_tf_train\n",
    ")\n",
    "\n",
    "# And now score the model on the training and test specimens....\n",
    "print(\n",
    "    pt_rf_model_1e_1_preterm.score(\n",
    "        X=pt_ra_1e_1_train,\n",
    "        y=preterm_tf_train\n",
    "    ),\n",
    "    pt_rf_model_1e_1_preterm.score(\n",
    "        X=pt_ra_1e_1_test,\n",
    "        y=preterm_tf_test\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "pt_rf_model_1e_1_early_preterm = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='sqrt',\n",
    "    random_state=12345\n",
    ").fit(\n",
    "    X=pt_ra_1e_1_train_early,\n",
    "    y=early_preterm_tf_train\n",
    ")\n",
    "\n",
    "# And now score the model on the training and test specimens....\n",
    "print(\n",
    "    pt_rf_model_1e_1_early_preterm.score(\n",
    "        X=pt_ra_1e_1_train_early,\n",
    "        y=early_preterm_tf_train\n",
    "    ),\n",
    "    pt_rf_model_1e_1_early_preterm.score(\n",
    "        X=pt_ra_1e_1_test_early,\n",
    "        y=early_preterm_tf_test\n",
    "    ),\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4872aa",
   "metadata": {},
   "source": [
    "Now let's plot some familiar ROC curves..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig, axes = plt.subplots(ncols=3, nrows=2, figsize=(12,8))\n",
    "\n",
    "    plot_roc_curve(\n",
    "        pt_rf_model_1e0_preterm,\n",
    "        X=pt_ra_1e0_test,\n",
    "        y=preterm_tf_test,\n",
    "        ax=axes[0,0]\n",
    "    )\n",
    "    axes[0,0].plot([0,1], [0,1])\n",
    "    \n",
    "    plot_roc_curve(\n",
    "        pt_rf_model_1e0_early_preterm,\n",
    "        X=pt_ra_1e0_test_early,\n",
    "        y=early_preterm_tf_test,\n",
    "        ax=axes[1,0]\n",
    "    )\n",
    "    axes[1,0].plot([0,1], [0,1])\n",
    "    axes[0,0].set_title(\"Phylotype distance 1.0\")\n",
    "    \n",
    "    axes[0,0].set_title(\"Phylotype distance 1.0\")\n",
    "    \n",
    "    ## --\n",
    "    plot_roc_curve(\n",
    "        pt_rf_model_5e_1_preterm,\n",
    "        X=pt_ra_5e_1_test,\n",
    "        y=preterm_tf_test,\n",
    "        ax=axes[0,1]\n",
    "    )\n",
    "\n",
    "    \n",
    "    plot_roc_curve(\n",
    "        pt_rf_model_5e_1_early_preterm,\n",
    "        X=pt_ra_5e_1_test_early,\n",
    "        y=early_preterm_tf_test,\n",
    "        ax=axes[1,1]\n",
    "    )    \n",
    "    \n",
    "    axes[0,1].plot([0,1], [0,1])\n",
    "    axes[1,1].plot([0,1], [0,1])\n",
    "    axes[0,1].set_title(\"Phylotype distance 0.5\")\n",
    "\n",
    "    #--\n",
    "    plot_roc_curve(\n",
    "        pt_rf_model_1e_1_preterm,\n",
    "        X=pt_ra_1e_1_test,\n",
    "        y=preterm_tf_test,\n",
    "        ax=axes[0,2]\n",
    "    )\n",
    "\n",
    "    \n",
    "    plot_roc_curve(\n",
    "        pt_rf_model_1e_1_early_preterm,\n",
    "        X=pt_ra_1e_1_test_early,\n",
    "        y=early_preterm_tf_test,\n",
    "        ax=axes[1,2]\n",
    "    )  \n",
    "    axes[1,2].plot([0,1], [0,1])\n",
    "    axes[0,2].plot([0,1], [0,1])\n",
    "    axes[0,2].set_title(\"Phylotype distance 0.1\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a049db",
   "metadata": {},
   "source": [
    "My conculusion was the models all perform reasonably well, and similarly / insensitive over this range of the the phylogenetic distance hyperparameter (0.1, 0.5, and 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865e050",
   "metadata": {},
   "source": [
    "## Dump models using the joblib dumps to be placed into the docker container\n",
    "\n",
    "For the challenge, these dumped model binaries will be placed into the docker container, loaded, and then applied to the phylotype tables from the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(pt_rf_model_1e0_preterm, 'models/preterm.rf_pt_1e0.save')\n",
    "dump(pt_rf_model_1e0_early_preterm, 'models/early_preterm.rf_pt_1e0.save')\n",
    "dump(pt_rf_model_1e_1_preterm, 'models/preterm.rf_pt_1e_1.save')\n",
    "dump(pt_rf_model_1e_1_early_preterm, 'models/early_preterm.rf_pt_1e_1.save')\n",
    "dump(pt_rf_model_5e_1_preterm, 'models/preterm.rf_pt_5e_1.save')\n",
    "dump(pt_rf_model_5e_1_early_preterm, 'models/early_preterm.rf_pt_5e_1.save')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c0dc0",
   "metadata": {},
   "source": [
    "There is repeated sampling, so what we *really* need is some way to predict on a per-participant not per-specimen basis. So, here is some sample code that *also* is used in the docker container to take the model's per-specimen prediction and convert it into a per-participant prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef80bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_5e_1_predicts = pd.DataFrame(\n",
    "    index=pt_ra_5e_1_test.index,\n",
    ")\n",
    "pt_5e_1_predicts['was_early_preterm'] = pt_rf_model_5e_1_early_preterm.predict(\n",
    "        pt_ra_5e_1_test\n",
    "    )\n",
    "pt_5e_1_predicts['was_preterm'] = pt_rf_model_5e_1_preterm.predict(\n",
    "        pt_ra_5e_1_test\n",
    "    )\n",
    "pt_5e_1_predicts['participant'] = pt_5e_1_predicts.index.map(specimen_participant.get)\n",
    "pt_5e_1_predicts.iloc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dede87eb",
   "metadata": {},
   "source": [
    ".. This again can be done better. Here we just take the maximum for each participant's specimens (i.e. if ANY are scored as preterm the entire participant is scored as preterm ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_5e_1_predicts_by_participant = pt_5e_1_predicts.groupby('participant').max()\n",
    "pt_5e_1_predicts_by_participant.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf158a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    roc_auc_score(\n",
    "        y_true=[\n",
    "            participant_preterm.get(p) for p in pt_5e_1_predicts_by_participant.index\n",
    "        ],\n",
    "        y_score=pt_5e_1_predicts_by_participant.was_preterm\n",
    "    ),\n",
    "    roc_auc_score(\n",
    "        y_true=[\n",
    "            participant_earlypreterm.get(p) for p in pt_5e_1_predicts_by_participant.index\n",
    "        ],\n",
    "        y_score=pt_5e_1_predicts_by_participant.was_early_preterm\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa02929",
   "metadata": {},
   "source": [
    "Same story for probability prediction of preterm.... We need to summarize this by participant from model scores by specimen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd614b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model = pt_rf_model_5e_1_early_preterm\n",
    "    pt = pt_ra_5e_1_test_early\n",
    "    predicts = pd.DataFrame(\n",
    "        [1 if p else 0 for p in model.predict(pt)],\n",
    "        index=pt.index,\n",
    "        columns=[f'was_early_preterm']\n",
    "    )\n",
    "    predicts['probability'] = [\n",
    "        v[1] for v in \n",
    "        model.predict_proba(\n",
    "            pt\n",
    "        )\n",
    "    ]\n",
    "    predicts['participant'] = predicts.index.map(specimen_participant.get)\n",
    "    \n",
    "    predicts.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts[\n",
    "    predicts.was_early_preterm == 1\n",
    "].iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_by_participant = predicts.groupby('participant').max().reset_index()\n",
    "predicts_by_participant['was_early_preterm'] = predicts_by_participant['was_early_preterm'].astype(int)\n",
    "predicts_by_participant.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f495b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts_by_participant[\n",
    "    predicts_by_participant.was_early_preterm == 1\n",
    "].iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b2d9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152095e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
